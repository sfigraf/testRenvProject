---
title: "Create Files for App Runscript"
author: "Sam Graf"
date: '2023-07-06'
output: html_document
---

```{r readins, include=FALSE, echo = FALSE}
library(tidyverse) 
library(lubridate)
library(readxl)
library(dataRetrieval) #this is the usgs package for getting up to date data
library(shiny) # only used for isTruthy(), found in getSequences
library(janitor)

whole_doc_startTime <- Sys.time()
start_time <- Sys.time()
print("Reading in Stationary, Mobile, Biomark, Release, and Recapture csv files.....")

#functions
for (i in list.files("./functions/")) {
  if (grepl(".R", i)) {
    source(paste0("./functions/",i))
  }
}

for (i in list.files("./miscR/")) {
  if (grepl(".R", i)) {
    source(paste0("./miscR/",i))
  }
}

# if column names change in any of these read-ins, might require some modification to code to get them to combine
# also if you change read.csv to read_csv, it should read in quicker but column names will change
# could be a later task
Stationary <- readRDS("./data/WGFP_Raw_20241204.rds")

Mobile <- read.csv("./data/WGFP_Mobile_Detect_AllData.csv" , colClasses= c(rep("character", 14), rep("numeric", 4), rep("character", 3)))

Biomark <- readRDS("./data/Biomark_Raw_20241111.rds")

# need to have tagID as a numeric field in the .csv file in order to be read in correctly as opposed to 2.3E+11 

Release <- read.csv("./data/WGFP_ReleaseData_Master_20241009.csv", na.strings = c(""," ","NA"), colClasses=c(rep("character",7), "numeric", "numeric",rep("character",9))) %>%
  janitor::remove_empty()
Recaptures <- read.csv("./data/WGFP_RecaptureData_Master_20241009.csv", na.strings = c(""," ","NA"), colClasses = c(rep("character", 7), rep("numeric", 2), rep("character", 8))) %>%
  janitor::remove_empty()

#avian predation
AvianPredation <- read_csv("./data/WGFP_AvianPredation.csv", 
                           col_types = cols(TagID = col_character(),Comments = col_character()))

#ghost tag df
GhostTags <- read_csv("./data/WGFP_GhostTags.csv", 
                           col_types = cols(TagID = col_character()))

#metadata

wgfpMetadata <- lapply(excel_sheets("./data/WGFP Metadata.xlsx"), function(x)
  if(x == "MarkerTagIssues"){
    read_excel("./data/WGFP Metadata.xlsx", sheet = x, col_types = c("guess", "date", "date", "guess", "guess"))
  } else{
    read_excel("./data/WGFP Metadata.xlsx", sheet = x, col_types = "text")
  }
)
names(wgfpMetadata) <- excel_sheets("./data/WGFP Metadata.xlsx")

###Pressure transducer Data
pTList <- list()

for (file in list.files("data/PressureTransducer")) {
  filereadin <- read_csv(file.path("data/PressureTransducer/", file))
  filename <- na.omit(unique(filereadin$Site))
  pTList[[filename]] <- filereadin
}

#binding all rows and getting names to be the same as the Site Visit Names; 
#important for assigning colors to sites and getting them to show up on graph
allPressureTransducerData <- bind_rows(pTList) %>%
  mutate(DateTime = lubridate::mdy_hm(DateTime)) %>%
  left_join(distinct(wgfpMetadata$AntennaMetadata[, c("PressureTransducerSiteName", "DetectionDistanceSiteName")]), by = c("Site" = "PressureTransducerSiteName")) %>%
  select(Site = DetectionDistanceSiteName, everything(), -Site)



## detection distance

siteVisitList <- lapply(excel_sheets("./data/WGFP_SiteVisits_FieldData.xlsx"), function(x){
  column_names <- read_excel("./data/WGFP_SiteVisits_FieldData.xlsx", sheet = x, skip = 2, n_max = 0)
  # Number of columns in the sheet
  num_cols <- length(column_names)
  # Specify the column types for the first 3 columns bc they have dates/times
  initial_col_types <- c("guess", "date", "date")
  col_types <- c(initial_col_types, rep("guess", num_cols - length(initial_col_types)))
  read_excel("./data/WGFP_SiteVisits_FieldData.xlsx", sheet = x, skip = 2, col_types = col_types)
}
  
)

names(siteVisitList) <- excel_sheets("./data/WGFP_SiteVisits_FieldData.xlsx")


end_time = Sys.time()

```

#### `r paste("Reading in input files took", round(difftime(end_time, start_time, units = "mins"),2), "minutes.")`

```{r USGSData, include = TRUE, echo = FALSE}
usgsTime <- Sys.time()
#reading in USGS data with upt to date data
windyGapDaily <- readNWISdv(siteNumbers = "09034250", #code for windy gap
                       parameterCd = c("00060", "00010"), #this is parameter codes for discharge and celsius water temp; more can be added if needed. https://help.waterdata.usgs.gov/codes-and-parameters/parameters
                       startDate = "2020-08-06", 
                       endDate = Sys.Date())
windyGapDaily <- renameNWISColumns(windyGapDaily) %>%
  mutate(WtempF = (Wtemp * 9/5) + 32)
#sometimes this can fail if USGS is having issues on their end
windyGap <- readNWISuv(siteNumbers = "09034250", #code for windy gap
                       parameterCd = c("00060", "00010"), #this is parameter code for discharge; more can be added if needed
                       startDate = "2020-08-06", #if you want to do times it is this format: "2014-10-10T00:00Z",
                       endDate = Sys.Date(),
                       tz = "America/Denver")

windyGap <- renameNWISColumns(windyGap) %>%
  mutate(Wtemp_Inst = (Wtemp_Inst * 9/5) + 32) %>%
  rename(USGSDischarge = Flow_Inst, 
         USGSWatertemp = Wtemp_Inst)
#this is to make attaching these readings to detections later
windyGap$dateTime <- lubridate::force_tz(windyGap$dateTime, tzone = "UTC") 

allPressureTransducerDataWithDischarge <- windyGap[,c("dateTime", "USGSDischarge", "USGSWatertemp")] %>%
  #we're going to get a "many" relationship here because the discharge is joined to each site reading so it causes each disharge timestamp that has a matching PT logger reading to get multiplied by at least 3 (1 for RB, HP, and CF)
  #another weird thing here: sometimes there is instances where USGSdischarge is recorded twice at the same time ie (2022-11-06 01:00:00)
  #but the values are within like 2 cfs of each other so it seems fine
  #this doesn't seem to happen with temperature
  left_join(allPressureTransducerData, by = c("dateTime"= "DateTime"), relationship = "many-to-many") %>%
  #we are getting rid of the "ice" entries here by turning them to 0
  mutate(Water_Level_NoIce_ft = as.numeric(case_when(Water_Level_NoIce_ft == "Ice" ~ "0", 
                                          TRUE ~ Water_Level_NoIce_ft)))

allPressureTransducerDataWithDischarge_Long <- allPressureTransducerDataWithDischarge %>%
  pivot_longer(cols = c(contains("_"), "USGSDischarge", "USGSWatertemp"), names_to = "EnvVariable", values_to = "Reading")

usgsTime2 <- Sys.time()
```
#### `r paste("Reading in USGS Data took", round(difftime(usgsTime2, usgsTime, units = "mins"), 2), "minutes.")`



```{r QAQCduplicateTags, include = FALSE, echo = FALSE}
#checking if ghost tags have 1 tag entry for each

problemGhostTags <- GhostTags %>%
  count(TagID) %>%
  filter(n > 1)

if(nrow(problemGhostTags) > 0){
  problemGhostTagsMessage <- paste0("The following tags in the Ghost Tag dataframe have multiple entries in the Ghost Tag sheet: ", unique(problemGhostTags$TagID),
                                         ". Please adjust this in the original df, otherwise there will be a left_join() warning.")
} else{
  problemGhostTagsMessage <- ""
}

problemAvianPredationTags <- AvianPredation %>%
  count(TagID) %>%
  filter(n > 1)

if(nrow(problemAvianPredationTags) > 0){
  problemAvianPredationTagsMessage <- paste0("The following tags in the Avian Predation dataframe have multiple entries: ", unique(problemAvianPredationTags$TagID),
                                         ". Please adjust this in the original df, otherwise there will be a left_join() warning.")
} else{
  problemAvianPredationTagsMessage <- ""
}

problemReleaseTags <- Release %>%
  count(TagID) %>%
  filter(n > 1)

if(nrow(problemReleaseTags) > 0){
 problemReleaseTagsMessage <- paste0("The following tags in the Release dataframe have multiple entries: ", as.character(unique(problemReleaseTags$TagID)),
                                         ". Please adjust this in the original df.")
} else {
  problemReleaseTagsMessage <- ""
}
```
<span style="color:red; font-size: 30px;" >`r problemGhostTagsMessage`</span>
<span style="color:red; font-size: 30px;" >`r problemAvianPredationTagsMessage`</span>
<span style="color:red; font-size: 30px;" >`r problemReleaseTagsMessage`</span>

```{r metadatavariables, include=FALSE, echo = FALSE}
###Variables that are used throughout the funcitons
###Frontend (display) codes
WindyGapBypassAntennaFrontendSiteCode <- as.character(wgfpMetadata$AntennaMetadata[!is.na(wgfpMetadata$AntennaMetadata$AntennaSite) & wgfpMetadata$AntennaMetadata$AntennaSite == "Windy Gap Bypass Channel", "FrontendSiteCode"])

WindyGapAuxiliaryAntennaFrontendSiteCode <- as.character(wgfpMetadata$AntennaMetadata[!is.na(wgfpMetadata$AntennaMetadata$AntennaSite) & wgfpMetadata$AntennaMetadata$AntennaSite == "Windy Gap Auxiliary", "FrontendSiteCode"])

GranbyDiversionAntennaFrontendSiteCode <- as.character(wgfpMetadata$AntennaMetadata[!is.na(wgfpMetadata$AntennaMetadata$AntennaSite) & wgfpMetadata$AntennaMetadata$AntennaSite == "Granby Diversion", "FrontendSiteCode"])

RiverRunAntennaFrontendSiteCode <- as.character(wgfpMetadata$AntennaMetadata[!is.na(wgfpMetadata$AntennaMetadata$AntennaSite) & wgfpMetadata$AntennaMetadata$AntennaSite == "River Run", "FrontendSiteCode"])

FraserRiverCanyonAntennaFrontendSiteCode <- as.character(wgfpMetadata$AntennaMetadata[!is.na(wgfpMetadata$AntennaMetadata$AntennaSite) & wgfpMetadata$AntennaMetadata$AntennaSite == "Fraser River Canyon", "FrontendSiteCode"])

RedBarnFrontendCodes <- unname(unlist(as.vector(wgfpMetadata$AntennaMetadata[!is.na(wgfpMetadata$AntennaMetadata$SiteName) & wgfpMetadata$AntennaMetadata$SiteName == "Red Barn Stationary Antenna", "FrontendSiteCode"])))

HitchingPostFrontendCodes <- unname(unlist(as.vector(wgfpMetadata$AntennaMetadata[!is.na(wgfpMetadata$AntennaMetadata$SiteName) & wgfpMetadata$AntennaMetadata$SiteName == "Hitching Post Stationary Antenna", "FrontendSiteCode"])))

ConfluenceFrontendCodes <- unname(unlist(as.vector(wgfpMetadata$AntennaMetadata[!is.na(wgfpMetadata$AntennaMetadata$SiteName) & wgfpMetadata$AntennaMetadata$SiteName == "Confluence Stationary Antenna", "FrontendSiteCode"])))

MobileRunFrontendCodes <- unname(unlist(as.vector(wgfpMetadata$AntennaMetadata[!is.na(wgfpMetadata$AntennaMetadata$SiteName) & wgfpMetadata$AntennaMetadata$SiteName == "Mobile Run", "FrontendSiteCode"])))

ConnectivityChannelDownstreamFrontendCodes <- unname(unlist(as.vector(wgfpMetadata$AntennaMetadata[!is.na(wgfpMetadata$AntennaMetadata$SiteName) & wgfpMetadata$AntennaMetadata$SiteName == "Connectivity Channel Downstream Stationary Antenna", "FrontendSiteCode"])))

ConnectivityChannelSideChannelFrontendCodes <- unname(unlist(as.vector(wgfpMetadata$AntennaMetadata[!is.na(wgfpMetadata$AntennaMetadata$SiteName) & wgfpMetadata$AntennaMetadata$SiteName == "Connectivity Channel Side Channel Stationary Antenna", "FrontendSiteCode"])))

ConnectivityChannelUpstreamFrontendCodes <- unname(unlist(as.vector(wgfpMetadata$AntennaMetadata[!is.na(wgfpMetadata$AntennaMetadata$SiteName) & wgfpMetadata$AntennaMetadata$SiteName == "Connectivity Channel Upstream Stationary Antenna", "FrontendSiteCode"])))

# ##############BACKEND CODES

WindyGapBypassAntennaBackendSiteCode <- as.character(wgfpMetadata$AntennaMetadata[!is.na(wgfpMetadata$AntennaMetadata$AntennaSite) & wgfpMetadata$AntennaMetadata$AntennaSite == "Windy Gap Bypass Channel", "BackendSiteCode"])

WindyGapAuxiliaryAntennaBackendSiteCode <- as.character(wgfpMetadata$AntennaMetadata[!is.na(wgfpMetadata$AntennaMetadata$AntennaSite) & wgfpMetadata$AntennaMetadata$AntennaSite == "Windy Gap Auxiliary", "BackendSiteCode"])


GranbyDiversionAntennaBackendSiteCode <- unlist(strsplit(as.character(wgfpMetadata$AntennaMetadata[!is.na(wgfpMetadata$AntennaMetadata$AntennaSite) & wgfpMetadata$AntennaMetadata$AntennaSite == "Granby Diversion", "BackendSiteCode"]), ",\\s*"))

RiverRunAntennaBackendSiteCode <- unlist(strsplit(as.character(wgfpMetadata$AntennaMetadata[!is.na(wgfpMetadata$AntennaMetadata$AntennaSite) & wgfpMetadata$AntennaMetadata$AntennaSite == "River Run", "BackendSiteCode"]), ",\\s*"))

FraserRiverCanyonAntennaBackendSiteCode <- unlist(strsplit(as.character(wgfpMetadata$AntennaMetadata[!is.na(wgfpMetadata$AntennaMetadata$AntennaSite) & wgfpMetadata$AntennaMetadata$AntennaSite == "Fraser River Canyon", "BackendSiteCode"]), ",\\s*"))

test_tags <- unique(wgfpMetadata$TestTags$TAG)
fraserColoradoRiverConfluence <- as.numeric(wgfpMetadata$ImportantStationingVariables[wgfpMetadata$ImportantStationingVariables$Variable == "Fraser/Colorado River Confluence", "StationingLocation"])

DamLocation <- as.numeric(wgfpMetadata$ImportantStationingVariables[wgfpMetadata$ImportantStationingVariables$Variable == "Windy Gap Dam", "StationingLocation"])

metaDataVariableNames <- list(
  "WindyGapBypassAntennaFrontendSiteCode" = WindyGapBypassAntennaFrontendSiteCode,
  "WindyGapAuxiliaryAntennaFrontendSiteCode" = WindyGapAuxiliaryAntennaFrontendSiteCode,
  "GranbyDiversionAntennaFrontendSiteCode" = GranbyDiversionAntennaFrontendSiteCode,
  "RiverRunAntennaFrontendSiteCode" = RiverRunAntennaFrontendSiteCode,
  "FraserRiverCanyonAntennaFrontendSiteCode" = FraserRiverCanyonAntennaFrontendSiteCode,
  "RedBarnFrontendCodes" = RedBarnFrontendCodes,
  "HitchingPostFrontendCodes" = HitchingPostFrontendCodes,
  "ConfluenceFrontendCodes" = ConfluenceFrontendCodes,
  "MobileRunFrontendCodes" = MobileRunFrontendCodes,
  "ConnectivityChannelDownstreamFrontendCodes" = ConnectivityChannelDownstreamFrontendCodes,
  "ConnectivityChannelSideChannelFrontendCodes" = ConnectivityChannelSideChannelFrontendCodes,
  "ConnectivityChannelUpstreamFrontendCodes" = ConnectivityChannelUpstreamFrontendCodes,
  "WindyGapBypassAntennaBackendSiteCode" = WindyGapBypassAntennaBackendSiteCode,
  "WindyGapAuxiliaryAntennaBackendSiteCode" = WindyGapAuxiliaryAntennaBackendSiteCode,
  "GranbyDiversionAntennaBackendSiteCode" = GranbyDiversionAntennaBackendSiteCode,
  "RiverRunAntennaBackendSiteCode" = RiverRunAntennaBackendSiteCode,
  "FraserRiverCanyonAntennaBackendSiteCode" = FraserRiverCanyonAntennaBackendSiteCode,
  "AntennaSiteShortHandCodes" = sort(unique(wgfpMetadata$AntennaMetadata$AntennaSiteShortHandShorthand)), 
  "allPressureTransducerSiteNames" = sort(unique(wgfpMetadata$AntennaMetadata$PressureTransducerSiteName)),
  "allDetectionDistanceSiteNames" = sort(unique(wgfpMetadata$AntennaMetadata$DetectionDistanceSiteName)),
  "test_tags" = test_tags,
  "fraserColoradoRiverConfluence" = fraserColoradoRiverConfluence,
  "DamLocation" = DamLocation
)

```

```{r cleaningForFunctions, include=FALSE, echo=FALSE}

#### This part is for checking if new antennas to be put in will work
#neeed to keep this in because it adds a column for the new antennas which sets up the enc_hist_wide_list$enc_wide_list for the new antennas
#the actual dummy tag is taken out at the end though

dummy_rows_list <- add_dummy_rows(stationary1 = Stationary, biomark1 = Biomark, release1 = Release)
#Stationary <- dummy_rows_list$Stationary
Biomark <- dummy_rows_list$Biomark
Release <- dummy_rows_list$Release
#ghost_tag_df <- dummy_rows_list$Ghost_tags #date column is named "Ghost_date" and is a date type

# Date Wrangling ----------------------------------------------------------

utmsStationary <- addUTMsAndReformatStationary(Stationary = Stationary)

# this readies raw files to be put into functions as well as displayed on Indivudal Datasets Page
Mobile <- Mobile %>%
    mutate(Date = as.character(lubridate::mdy(Date)))


Biomark <- Biomark %>%
  #make a column for Scan>Date if parentheses are detected in the string, that means the format is in mdy
  # and we want to convert it to YYYYMMDD format. elsewise, leave it as is
  mutate(`Scan Date` = ifelse(str_detect(`Scan Date`, "/"),
                            as.character(lubridate::mdy(`Scan Date`)),
                            `Scan Date`))


cleanedRelease <- Release %>%
  mutate(Date = as.character(lubridate::mdy(Date)), 
         Species = str_trim(Species))

cleanedRecaptures <- Recaptures %>%
  mutate(Date = as.character(lubridate::mdy(Date)), 
         Species = str_trim(Species)
  )

AvianPredation <- AvianPredation %>%
  mutate(PredationDate = lubridate::mdy(PredationDate))

GhostTags <- GhostTags %>%
  mutate(GhostDate = lubridate::mdy(GhostDate))
```

```{r wrangling, include = FALSE, echo = FALSE}


#putting detection data into a function that cleans and readies data for wrangling, display, filtering, mapping, plotting
AllCombinedEvents <- All_combined_events_function(Stationary = utmsStationary, Mobile = Mobile, Release = Release, Biomark = Biomark, Recaptures = Recaptures)

#separating to marker tag file and fish detections file

#all marker tags here
Cleaned_Marker_tags <- AllCombinedEvents$df_list$All_Detections %>%
  dplyr::filter(str_detect(TAG, "^0000000|^999")) %>%
  mutate(Scan_Date = ymd(Scan_Date))

Cleaned_Stationary_FishdetectionsOnly <- utmsStationary %>%
  filter(grepl("^230|^226", TAG))


#spatially joins point (detection) data to lines (station) data based on nearest feature, and joins detections to States polygon as well based on intersection
#simpleStations and WGFP_States_2024 are from polygon_readins
DailyDetectionsStationsStates <- spatial_join_stations_detections(condensedEvents = AllCombinedEvents$df_list$All_Events_most_relevant, simpleStations = simpleStations, WGFP_States_2024)


problemNAtagsMessage <- ifelse(nrow(DailyDetectionsStationsStates$spatialList$noUTMS) > 0, 
                               paste0("The following tags could not be assigned stations because of an NA entry for UTMs: ", unique(DailyDetectionsStationsStates$spatialList$noUTMS$TAG),
                                         "."), 
                               "")

problemNoStatetagsMessage <- ifelse(nrow(DailyDetectionsStationsStates$spatialList$noState) > 0,
                                    paste0("The following tags could not be assigned a state (aside from TGM) because their boundary was outside the states polygon: ", unique(DailyDetectionsStationsStates$spatialList$noState$TAG),
                                         "."), 
                                    ""
                                    )

encounterMARKStates <- createMARKEncounterHistories(DailyDetectionsStationsStates$spatialList$stationData, GhostTags, AvianPredation, wgfpMetadata$TimePeriods)

#prepares joined stations and relevant Movements dataset for movements summaries and states
#Not sure if I need this function to be this extensive with the new state regime
combined_events_stations <- PrepareforStatesMovementsandSummary(DailyDetectionsStationsStates$spatialList$stationData)

# states

# aplies enc_hist_summary wide function
enc_hist_wide_list <- Ind_tag_enc_hist_wide_summary_function(AllCombinedEvents$df_list$Recaps_detections, cleanedRelease, combined_events_stations, encounterMARKStates$States_summarized, markerTags = unique(Cleaned_Marker_tags$TAG))
unknown_tags <- enc_hist_wide_list$enc_wide_list$Unknown_Tags
enc_hist_wide_df <- enc_hist_wide_list$enc_wide_list$encountersAndRelease_wide_summary
# applies get_movements_function
Movements_list <- get_movements_function(combined_events_stations, dailyUSGSData = windyGapDaily)
WeeklyMovementsbyType <- WrangleMinicharts_function(Movements_list$dailyMovementsTable1)

### Avian Predation: grouping together different methods of finding avian predated fish

allEventsAvianPredationFiltered <- AllCombinedEvents$df_list$All_Events %>%
  dplyr::filter(!TAG %in% unique(AvianPredation$TagID))

movingDownstream <- getSequences(allEventsAvianPredationFiltered, c("CF", "GD1", "RR1"), "", c("HP", "RB", "WG1", "WG2"), c("M1", "M2"))
movingUpstream <- getSequences(allEventsAvianPredationFiltered, c("HP", "RB", "WG1", "WG2") , "", c("CF", "GD1", "RR1"), c("M1", "M2"))

avianPredationList <- list(
  "movingDownstream" = movingDownstream, 
  "movingUpstream" = movingUpstream, 
  "largeMovementsWithoutChannel" = enc_hist_wide_list$enc_wide_list$possibleAvianPredation, 
  "statesWeeklyActiveFish" = encounterMARKStates$possibleAvianPredation$weeklyActiveFish, 
  "statesAllActiveFish" = encounterMARKStates$possibleAvianPredation$overAllActiveFishNotinWeeklyDF, 
  "fastMovements" = Movements_list$avianPredationDFS$fastMovements,
  "longMovements" = Movements_list$avianPredationDFS$longMovements
  )
#removing all tags already discerned as avian predation from each df
avianPredationList <- purrr::map(avianPredationList, ~anti_join(.x, AvianPredation, by = c("TAG" = "TagID")))

###making df of frequency counts for each time a fish appears on a df to get "priority" list
tagCountsNoPredation <- purrr::map_dfr(avianPredationList, ~ {
  # Count occurrences within this dataframe
  .x %>%
    count(TAG)
}) %>%
  # Summarize counts across all dataframes
  group_by(TAG) %>%
  summarize(Frequency = sum(n), .groups = 'drop') %>%
  arrange(desc(Frequency))

avianPredationList[["tagCountsNoPredation"]] = tagCountsNoPredation
#adding checked tags to the list
checkedTags <- read_csv("data/Potential Avian Predated tags.csv") #Potential Avian Predated tags

checkedTags$TAG <- as.character(checkedTags$TAG)
avianPredationList <- purrr::map(avianPredationList, ~{
  originalColumns <- names(.x)
  outputDatWithCheckedTags <- left_join(.x, checkedTags, by = "TAG")
  outputDatWithRowColor <- outputDatWithCheckedTags %>%
    mutate(rowColor = case_when(`SG Opinion` %in% c("Yes", "yes") ~ "red", 
                                `SG Opinion` %in% c("No", "no") ~ "green", 
                                !is.na(`SG Opinion`) ~ "yellow", 
                                is.na(`SG Opinion`) ~ "none"
    )) %>%
    select(c(originalColumns, rowColor))
  return(outputDatWithRowColor)
}
)
                                 
###QAQC ghost tags
ghostTagsWithMovementAfterGhostDate <- qaqcGhostTagMovements(GhostTags, Movements_list$dailyMovementsTable1)

#more formatting
Enc_release_data <- enc_hist_wide_df %>%
    mutate(Date = ifelse(str_detect(Date, "/"),
                         as.character(lubridate::mdy(Date)),
                         Date)) %>%
  rename(ReleaseDate = Date)


# if someone could incorporate and expland upon this custom rainbow trout color pallette I made that would be great
rainbow_trout_pallette <- list(pink1 = "#E3BABBFF", olive_green1 = "#C4CFBFFF", dark_olive_green1 = "#81754EFF",
                               mustard_yellow1 = "#CBA660FF", brown_yellow = "#86551CFF" )

WGFP_SiteVisits_FieldData <- wrangleSiteVisitData(siteVisitList = siteVisitList)
WGFP_SiteVisits_FieldDatawithPTData <- combineEnvironmentalAndSiteVisitData(WGFPSiteVisitsFieldData = WGFP_SiteVisits_FieldData, PTDataWide = allPressureTransducerDataWithDischarge)

### taking dummy tag out

Biomark <- Biomark %>%
  filter(!`DEC Tag ID` %in% c("900.230000999999"))
cleanedRelease <- cleanedRelease %>%
  filter(!TagID %in% c("230000999999"))
Stationary <- Cleaned_Stationary_FishdetectionsOnly %>%
  filter(!TAG %in% c("900230000999999"))

#this list is taken by the individual datasets mod
indiv_datasets_list_og <- list(
  "stationarycleandata" = Stationary,
  "biomarkdata" = Biomark,
  "mobiledata" = Mobile,
  "recapdata" = cleanedRecaptures,
  "releasedata" = cleanedRelease,
  "ghostdata" = GhostTags,
  "avian_preddata" = AvianPredation, 
  "PTDataRawCombined" = allPressureTransducerData,
  "USGSData15Min" = windyGap,
  "SiteVisitDataCombined" = WGFP_SiteVisits_FieldData
)

indiv_datasets_list <- lapply(names(indiv_datasets_list_og), function(name) {
  dataset <- indiv_datasets_list_og[[name]]
  if (name %in% c("PTDataRawCombined", "USGSData15Min", "SiteVisitDataCombined")) {
    return(dataset)  # Skip processing for these datasets
  } else {
    # Perform the cleaning operation
    return(dataset[!apply(is.na(dataset) | dataset == "", 1, all), ])
  }
})
names(indiv_datasets_list) <- names(indiv_datasets_list_og)

movements_list <- list(
  "Movements_df" = Movements_list$dailyMovementsTable1,
  "WeeklyMovementsbyType" = WeeklyMovementsbyType, 
  "ghostTagsWithMovementAfterGhostDate" = ghostTagsWithMovementAfterGhostDate
)

PTData <- list(
  "PTDataWide" = allPressureTransducerDataWithDischarge, 
  "PTDataLong" = allPressureTransducerDataWithDischarge_Long
)

USGSData <- list(
  "USGS15Min" = windyGap, 
  "USGSDaily" = windyGapDaily
)

SiteVisitData <- list(
  "WGFP_SiteVisits_FieldData" = WGFP_SiteVisits_FieldData, 
  "SiteVisitAndPTData" = WGFP_SiteVisits_FieldDatawithPTData
)



```

#### `r AllCombinedEvents$endMessage`
#### `r DailyDetectionsStationsStates$endMessage`
#### `r encounterMARKStates$endMessage`
#### `r enc_hist_wide_list$endMessage`
#### `r Movements_list$message`


<span style="color:red; font-size: 30px;" >`r problemNAtagsMessage`</span>
<span style="color:red; font-size: 30px;" >`r problemNoStatetagsMessage`</span>
<span style="color:red; font-size: 30px;" >`r encounterMARKStates$timePeriodsMessage`</span>


```{r saveFiles, include = FALSE, echo=FALSE}
saveFilestartTime <- Sys.time()
allFlatFiles <- list(
  "combinedData_df_list" = AllCombinedEvents$df_list,
  "indiv_datasets_list" = indiv_datasets_list,
  "Enc_release_data" = Enc_release_data,
  "encounterMARKStates" = encounterMARKStates,
  "movements_list" = movements_list,
  "Marker_tags" = Cleaned_Marker_tags,
  "unknown_tags" = unknown_tags, 
  "possibleAvianPredationDFs" = avianPredationList,
  "wgfpMetadata" = wgfpMetadata,
  "metaDataVariableNames" = metaDataVariableNames,
  "PTData" = PTData,
  "USGSData" = USGSData, 
  "SiteVisitData" = SiteVisitData
)

for(filename in names(allFlatFiles)){
  saveRDS(allFlatFiles[[filename]], paste0("data/flatFilesforApp/", filename, ".rds"))
}
saveFilesEndTime <- Sys.time()

savingFilesEndMessage <- paste("Saving flat files for the app took", round(difftime(saveFilesEndTime, saveFilestartTime, units = "mins"),2), "minutes.")

whole_doc_endTime <- Sys.time()
```

#### `r savingFilesEndMessage`
## `r paste("The whole document took", round(whole_doc_endTime-whole_doc_startTime,2), "minutes to run.  Flat Files are saved to the flat files directory and the data vis app is ready to run with the most updated data.")`
