theme(axis.line = element_line(colour = "black"),
panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
panel.border = element_blank(),
panel.background = element_blank(),
plot.title = element_text(hjust = 0.5, size=35), # centers title
axis.title=element_text(size=45),
axis.text.y=element_text(size=55, colour="black"),
axis.text.x=element_text(size=0, colour="black"),
legend.title=element_text(size=45),
legend.text=element_text(size=45),
legend.position = c(0.85, .7), # c(.15, .65)
axis.title.y=element_text(margin=margin(0,20,0,0), size=45),
axis.title.x=element_text(margin=margin(20,0,0,0))) +
scale_y_continuous(limits = c(1.75, 5)) +
labs(y="Age", x="Spotting Type", main="") # +
ggplot(data=age.means, aes(x=Spots, y=emmean, color=Spots), ylim=c(0,5)) + # title="Fp Only",  xlim=c(0,29),
scale_color_manual(values=c("black", "orange", "red")) +
geom_point(data=age.means, size=10 ) + # , aes(shape=Strain)
geom_errorbar(data=age.means, aes(ymin=lower.CL, ymax=upper.CL), width=.2, position=position_dodge(0.05), size=2) +
# ggtitle("Fp Only") +
# ylim(0,1) +
theme_bw() +
theme(axis.line = element_line(colour = "black"),
panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
panel.border = element_blank(),
panel.background = element_blank(),
plot.title = element_text(hjust = 0.5, size=35), # centers title
axis.title=element_text(size=45),
axis.text.y=element_text(size=55, colour="black"),
axis.text.x=element_text(size=0, colour="black"),
legend.title=element_text(size=45),
legend.text=element_text(size=45),
legend.position = c(0.85, .7), # c(.15, .65)
axis.title.y=element_text(margin=margin(0,20,0,0), size=45),
axis.title.x=element_text(margin=margin(20,0,0,0))) +
scale_y_continuous(limits = c(1.75, 4.6)) +
labs(y="Age", x="Spotting Type", main="") # +
ggplot(data=age.means, aes(x=Spots, y=emmean, color=Spots), ylim=c(0,5)) + # title="Fp Only",  xlim=c(0,29),
scale_color_manual(values=c("black", "orange", "red")) +
geom_point(data=age.means, size=10 ) + # , aes(shape=Strain)
geom_errorbar(data=age.means, aes(ymin=lower.CL, ymax=upper.CL), width=.2, position=position_dodge(0.05), size=2) +
# ggtitle("Fp Only") +
# ylim(0,1) +
theme_bw() +
theme(axis.line = element_line(colour = "black"),
panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
panel.border = element_blank(),
panel.background = element_blank(),
plot.title = element_text(hjust = 0.5, size=35), # centers title
axis.title=element_text(size=45),
axis.text.y=element_text(size=55, colour="black"),
axis.text.x=element_text(size=0, colour="black"),
legend.title=element_text(size=45),
legend.text=element_text(size=45),
legend.position = c(0.85, .7), # c(.15, .65)
axis.title.y=element_text(margin=margin(0,20,0,0), size=45),
axis.title.x=element_text(margin=margin(20,0,0,0))) +
scale_y_continuous(limits = c(1.75, 4.5)) +
labs(y="Age", x="Spotting Type", main="") # +
library(rstan)
rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores())
library(MCMCvis)
# library(mygmailR)
# Base simulation function
# initial N starts at 14,000, 20 total occasions (Nocc), 1st 10 with only count data, 2nd 10 sith Mark Recap + count data, NMRocc = Number of MR occasions = 10, MRstart = when MR starts (occasion 11),
# Number of recruits is Nrec, low rec = 1000, medium = 4000, high = 16000,
sim_intre <- function(mu_lphi=1.1,sd_lphi=.124,mu_lp=-2.5,sd_lp=.124,mu_lq=-2.5,sd_lq=.124,beta_phi=0.217,beta_p=0.217,beta_q=0.217,
beta_nrec=0.979, sd_lrec=0.564, mu_lrec=8.3,
Ninit = 14000,NMRocc=10,MRstart=11,Nocc=20){ #Nrec = rlnorm(19,8.3,1.13)
###
# adding covariates
###
# random covariate values
X_phi <- rnorm((Nocc-1),0,1)
X_p <- rnorm(NMRocc,0,1)
X_q <- rnorm(Nocc,0,1)
X_q2 <- rnorm(Nocc,0,1)
X_nrec <- rnorm((Nocc-1),0,1)
###
# Have the detection and survival beta_0 be the original settings.
###
phi_0 <- rnorm((Nocc-1),mu_lphi,sd_lphi) # survival
p_0 <- rnorm(NMRocc,mu_lp,sd_lp) # detection for mark recapture
q_0 <- rnorm(Nocc,mu_lq,sd_lq) # detection for count data
q2_0 <- rnorm(Nocc,mu_lq,sd_lq) # second pass count detection
rec_0 <- rnorm((Nocc-1),mu_lrec,sd_lrec)
phi <- plogis(phi_0 + (beta_phi*X_phi))
p <- plogis(p_0 + (beta_p*X_p))
q <- plogis(q_0 + (beta_q*X_q))
q2 <- plogis(q2_0 + (beta_q*X_q2))
N<-numeric()
Nrec_c <- exp(rec_0 + (beta_nrec*X_nrec))
Nrec_c<- round(Nrec_c,0) # need to round the values to allow rbinom to work correctly...
N[1]<-Ninit
for (t in 2:Nocc){
N[t]<-rbinom(1,N[(t-1)],phi[(t-1)])+Nrec_c[(t-1)] # N[t] = random number from binomial, pick 1 value, size= N[(t-1)], prob = phi[(t-1)] (survival) + number of recruits; populate abundance using previous (t-1) abundance
}
Nentered<-cumsum(c(N[MRstart],Nrec_c[MRstart:(Nocc-1)])) # number of fish entering
Nsuper<-N[MRstart]+sum(Nrec_c[MRstart:(Nocc-1)]) # super population number
Z<-matrix(0, ncol = NMRocc, nrow = Nsuper) # Z is true value of fish being alive, 1 or 0
CH<-matrix(0, ncol = NMRocc, nrow = Nsuper) # capture history
Z[1:N[MRstart],1]<-1 # all the fish in the first mark recap are truly alive
CH[,1]<-rbinom(Nsuper,1,Z[,1]*p[1]) # population the capture history
for (t in 2:NMRocc){
Z[,t]<-rbinom(Nsuper,1,Z[,(t-1)]*phi[(MRstart+t-2)]) # survive individuals already in population
if (Nentered[t]>Nentered[t-1]) {
Z[(1+Nentered[t-1]):(Nentered[t]),t]<-1
}
CH[,t]<-rbinom(Nsuper,1,Z[,t]*p[t])
}
# Remove individuals never captured
CHsum <- rowSums(CH)
keep <- which(CHsum > 0)
ch<-CH[keep,]
ch_char = apply(ch, 1, function(x) paste(x, collapse = ","))
sumCH = t(sapply(strsplit(names(table(ch_char)), split = ","),
as.numeric))
tFR = as.numeric(as.vector(table(ch_char)))
tfd <- apply(sumCH,1,function(x) which(x==1)[1])
MRcount <- colSums(CH)
tY <- ifelse(sumCH==0,2,1)
# Remove individuals seen only in last occasion
fd<-subset(tfd,tfd!=Nocc)
FR<-subset(tFR,tfd!=Nocc)
Y<-tY[which(tfd!=Nocc),]
NCH <- dim(Y)[1]
othercount<-rbinom(Nocc,N,q)
othercount2<-rbinom(Nocc,N,q2)
return(list(Nocc=Nocc,NCH=NCH,FR=FR,Y=Y,fd=fd,MRcount=MRcount,MRstart=MRstart,NMRocc=NMRocc,othercount=othercount,othercount2=othercount2,Nz=c(Ninit,Nrec_c),N=N,
X_phi=X_phi,X_p=X_p,X_q=X_q,X_nrec=X_nrec))
}
###############################################################################################################################################################################################
###############################################################################################################################################################################################
###
# Detections
###
n.iter = 10000
parz<- c("Nrec","phi","p","q","N",
"beta_phi","beta_p","beta_q","beta_nrec",
"sd_lphi", "sd_lp", "sd_lq", "sd_lrec",
"mu_lphi", "mu_lp", "mu_lq", "mu_lrec")
###
# p = 0.25, q=0.25, phi=0.75
# sd = 0.5
###
trueNZ1<-matrix(NA,ncol=20,nrow=33)
trueN1<-matrix(NA,ncol=20,nrow=33)
output_T1<-array(NA,dim=c(100,8,33))
rHat1<-matrix(NA,ncol=33, nrow=100)
time_T1<-matrix(NA,ncol=1,nrow=33)
i=1
temp1<-sim_intre(mu_lp=-1.11,sd_lp=.5,mu_lq=-1.11,sd_lq=.5) # make data from simulated data
trueNZ1[i,]<-temp1$Nz
trueN1[i,]<-temp1$N
data_JS1<-temp1[1:8]
data_int1<-temp1[c(1:9,13:16)]
# M_JS<-stan("JS_re.stan",data = data_JS, pars=parz,chains = 3, iter =7000)
cov_part1<-stan("~/Documents/Fish/Post_Doc/Simmulated Data with Charles/int_JS from Charles/trout_with_JK/sims/stage_2_base/REpois_pT_qT_phiT_lognorm_rand_prob_uniform_N1_lognormal_Nrec_cov_15May2024.stan",
data = data_int1,pars=parz,chains = 3, iter = n.iter, control=list(max_treedepth=12)) # control=list(max_treedepth=14)
T_conv.test1 <- max(summary(cov_part1)$summary[1:100,10])
T_conv.test1>1.05
T_conv.test1
T_conv.test1 > 1.05
if(T_conv.test1>1.05){
new.iter <- (n.iter+20000)
while(T_conv.test1>1.05){
cov_part1<-stan("~/Documents/Fish/Post_Doc/Simmulated Data with Charles/int_JS from Charles/trout_with_JK/sims/stage_2_base/REpois_pT_qT_phiT_lognorm_rand_prob_uniform_N1_lognormal_Nrec_cov_15May2024.stan",
data = data_int1, pars=parz,chains = 3, iter = new.iter, control=list(max_treedepth=12))
T_conv.test1 <- max(summary(cov_part1)$summary[1:100,10])
if(T_conv.test1>1.05){
new.iter <- new.iter + 20000
}
}
}
load("/Volumes/BACKUPCSU/Grand_Canyon_1500itter.RData")
library(rstan)
options(mc.cores = parallel::detectCores())
# rstan_options(auto_write = TRUE)
library(MCMCvis)
library(tictoc)
MCMCsummary(GC.Int.Full.Rand.pcpue.test.out)
Look <- MCMCsummary(GC.Int.Full.Rand.pcpue.test.out)
write.csv(Look, "~/Documents/Fish/PostDoc Bill Kendall Charles Y/Integrated/Stan Code after Likelihood/Parms 24June2024 run from Bill Computer.csv")
1250*2
exp(6)
exp(9)
inv_logit(3.3)
inv_logit(2.4)
inv_logit(3.3+0.54)
inv_logit(2.4+0.54)
inv_logit(-3.3)
inv_logit(-7.3)
inv_logit(-5.8)
inv_logit(-3.7)
inv_logit(-4.67)
1-0.003
1-0.024
1-0.00928
exp(2.3)
exp(1.5)
up<-1.509558047
down<-2.32273495
exp(down)/(3 + exp(down))
1/(3 + exp(down))
exp(up)/(2+exp(up)+exp(down))
exp(down)/(2+exp(up)+exp(down))
exp(up)/(2 + exp(up) + exp(down))
exp(down)/(2 + exp(up) + exp(down))
exp(up)/(2 + exp(up) + exp(down))
inv_logit(-5.8+1.33)
inv_logit(-3.7+1.33)
inv_logit(-1.6)
inv_logit(-5)
inv_logit(-3.4)
inv_logit(-4)
inv_logit(-7.27)
inv_logit(0.7)
inv_logit(-3.4+0.7)
inv_logit(-4+0.7)
inv_logit(-7.3+0.7)
inv_logit(-1.6)
inv_logit(-2)
inv_logit(-5)
inv_logit(-4)
exp(6)
exp(9)
?tree()
library(rstan)
rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores())
library(MCMCvis)
# initial N starts at 14,000, 20 total occasions (Nocc), 1st 10 with only count data, 2nd 10 sith Mark Recap + count data, NMRocc = Number of MR occasions = 10, MRstart = when MR starts (occasion 11),
# Number of recruits is Nrec, low rec = 1000, medium = 4000, high = 16000,
sim_intre <- function(mu_lphi=1.1,sd_lphi=.124,mu_lp=-2.5,sd_lp=.124,mu_lq=-2.5,sd_lq=.124,beta_phi=0.217,beta_p=0.217,beta_q=0.217,
beta_nrec=0.979, sd_lrec=0.564, mu_lrec=8.3,
Ninit = 14000,NMRocc=10,MRstart=11,Nocc=20){ #Nrec = rlnorm(19,8.3,1.13)
###
# adding covariates
###
# random covariate values
X_phi <- rnorm((Nocc-1),0,1)
X_p <- rnorm(NMRocc,0,1)
X_q <- rnorm(Nocc,0,1)
X_q2 <- rnorm(Nocc,0,1)
X_nrec <- rnorm((Nocc-1),0,1)
###
# Have the detection and survival beta_0 be the original settings.
###
phi_0 <- rnorm((Nocc-1),mu_lphi,sd_lphi) # survival
p_0 <- rnorm(NMRocc,mu_lp,sd_lp) # detection for mark recapture
q_0 <- rnorm(Nocc,mu_lq,sd_lq) # detection for count data
q2_0 <- rnorm(Nocc,mu_lq,sd_lq) # second pass count detection
rec_0 <- rnorm((Nocc-1),mu_lrec,sd_lrec)
phi <- plogis(phi_0 + (beta_phi*X_phi))
p <- plogis(p_0 + (beta_p*X_p))
q <- plogis(q_0 + (beta_q*X_q))
q2 <- plogis(q2_0 + (beta_q*X_q2))
N<-numeric()
Nrec_c <- exp(rec_0 + (beta_nrec*X_nrec))
Nrec_c<- round(Nrec_c,0) # need to round the values to allow rbinom to work correctly...
N[1]<-Ninit
for (t in 2:Nocc){
N[t]<-rbinom(1,N[(t-1)],phi[(t-1)])+Nrec_c[(t-1)] # N[t] = random number from binomial, pick 1 value, size= N[(t-1)], prob = phi[(t-1)] (survival) + number of recruits; populate abundance using previous (t-1) abundance
}
Nentered<-cumsum(c(N[MRstart],Nrec_c[MRstart:(Nocc-1)])) # number of fish entering
Nsuper<-N[MRstart]+sum(Nrec_c[MRstart:(Nocc-1)]) # super population number
Z<-matrix(0, ncol = NMRocc, nrow = Nsuper) # Z is true value of fish being alive, 1 or 0
CH<-matrix(0, ncol = NMRocc, nrow = Nsuper) # capture history
Z[1:N[MRstart],1]<-1 # all the fish in the first mark recap are truly alive
CH[,1]<-rbinom(Nsuper,1,Z[,1]*p[1]) # population the capture history
for (t in 2:NMRocc){
Z[,t]<-rbinom(Nsuper,1,Z[,(t-1)]*phi[(MRstart+t-2)]) # survive individuals already in population
if (Nentered[t]>Nentered[t-1]) {
Z[(1+Nentered[t-1]):(Nentered[t]),t]<-1
}
CH[,t]<-rbinom(Nsuper,1,Z[,t]*p[t])
}
# Remove individuals never captured
CHsum <- rowSums(CH)
keep <- which(CHsum > 0)
ch<-CH[keep,]
ch_char = apply(ch, 1, function(x) paste(x, collapse = ","))
sumCH = t(sapply(strsplit(names(table(ch_char)), split = ","),
as.numeric))
tFR = as.numeric(as.vector(table(ch_char)))
tfd <- apply(sumCH,1,function(x) which(x==1)[1])
MRcount <- colSums(CH)
tY <- ifelse(sumCH==0,2,1)
# Remove individuals seen only in last occasion
fd<-subset(tfd,tfd!=Nocc)
FR<-subset(tFR,tfd!=Nocc)
Y<-tY[which(tfd!=Nocc),]
NCH <- dim(Y)[1]
othercount<-rbinom(Nocc,N,q)
othercount2<-rbinom(Nocc,N,q2)
return(list(Nocc=Nocc,NCH=NCH,FR=FR,Y=Y,fd=fd,MRcount=MRcount,MRstart=MRstart,NMRocc=NMRocc,othercount=othercount,othercount2=othercount2,Nz=c(Ninit,Nrec_c),N=N,
X_phi=X_phi,X_p=X_p,X_q=X_q,X_nrec=X_nrec))
}
n.iter = 3000
parz<- c("Nrec","phi","p","q","N",
"beta_nrec",  # "beta_phi", "beta_p", "beta_q",,,
"sd_lp", "sd_lq", "sd_lNrec", "sd_lphi",
"mu_lp", "mu_lq", "mu_lNrec", "mu_lphi" )
trueNZ1<-matrix(NA,ncol=20,nrow=100)
trueN1<-matrix(NA,ncol=20,nrow=100)
output_T1<-array(NA,dim=c(100,8,100))
rHat1<-matrix(NA,ncol=100, nrow=100)
time_T1<-matrix(NA,ncol=1,nrow=100)
i=1
temp1<-sim_intre(mu_lp=-1.11,sd_lp=.5,mu_lq=-1.11,sd_lq=.5) # make data from simulated data
trueNZ1[i,]<-temp1$Nz
trueN1[i,]<-temp1$N
data_JS1<-temp1[1:8]
data_int1<-temp1[c(1:9,13:16)]
# M_JS<-stan("JS_re.stan",data = data_JS, pars=parz,chains = 3, iter =7000)
cov_part1<-stan("~/Documents/Fish/Post_Doc/Simmulated Data with Charles/int_JS from Charles/trout_with_JK/sims/stage_2_base/REpois_pT_qT_phiT_lognorm_rand_prob_uniform_N1_lognormal_Nrec_nrecOnly_cov_13Aug2024.stan",
data = data_int1,pars=parz,chains = 3, iter = n.iter, control=list(max_treedepth=14)) # control=list(max_treedepth=14)
# M_JS<-stan("JS_re.stan",data = data_JS, pars=parz,chains = 3, iter =7000)
cov_part1<-stan("~/Documents/Fish/Post_Doc/Simmulated Data with Charles/int_JS from Charles/trout_with_JK/sims/stage_2_base/REpois_pT_qT_phiT_lognorm_rand_prob_uniform_N1_lognormal_Nrec_nrecOnly_cov_13Aug2024.stan",
data = data_int1,pars=parz,chains = 3, iter = n.iter, control=list(max_treedepth=14)) # control=list(max_treedepth=14)
parz<- c("Nrec","phi","p","q","N",
"beta_nrec",  # "beta_phi", "beta_p", "beta_q",,,
"sd_lp", "sd_lq", "sd_lrec", "sd_lphi",
"mu_lp", "mu_lq", "mu_lrec", "mu_lphi" )
# M_JS<-stan("JS_re.stan",data = data_JS, pars=parz,chains = 3, iter =7000)
cov_part1<-stan("~/Documents/Fish/Post_Doc/Simmulated Data with Charles/int_JS from Charles/trout_with_JK/sims/stage_2_base/REpois_pT_qT_phiT_lognorm_rand_prob_uniform_N1_lognormal_Nrec_nrecOnly_cov_13Aug2024.stan",
data = data_int1,pars=parz,chains = 3, iter = n.iter, control=list(max_treedepth=14)) # control=list(max_treedepth=14)
T_conv.test1 <- max(summary(cov_part1)$summary[1:98,10])
summary(cov_part1)$summary
setwd("/Volumes/CPW_Work/Optimum Sampling/Ark_Optimal_bwa/Source_Files")  # Fill in as appropriate
### Required packages:
library(animation)  # for kfcv function
library(boot)  # for logit functions
library(R2jags)  # to run the models
library(mcmcplots)  # to check model convergence
library(verification)  # to calc AUC statistic (used in functions)
library(matrixStats)
### Import the data and source functions -----------------------
load("/Volumes/CPW_Work/Optimum Sampling/Ark_Optimal_bwa/Output_Files/ArkData.RData")
source("ArkFunctions.R")
### Set up for all models, all cross-validation data sets ---------------
set.seed(2000)
# Number of coef/covariates of each model:
nPsiList <- c(17, 17, 15, 9, 7, 10, 8, 9, 6, 10, 10,
7, 6, 9, 2, 2, 5, 5, 5, 5, 2, 2, 2,
2, 2, 2, 5, 3)
nDetList <- c(28, rep(12, 3), 13, 11, rep(10, 4), 11,
13, 12, 12, 12, 10, 12, 10, 13, 10, 11, 4, 11,
4, 3, 4, 3, 4)
nModels <- length(nPsiList)
# Tell JAGS what variables to save for output
params <- c("muPsiCoef", "sigmaPsiCoef",
"muDetCoef", "sigmaDetCoef",
"detCoef", "psiCoef", "score01ij")
# Convert the SDs in the prior distributions to precisions for JAGs
muPsiCoef.tau <- 1 / 2.25 ^ 2
muDetCoef.tau <- 1 / 2.25 ^ 2
t.tau <- 1 / 2.25 ^ 2
# Tell JAGS what variables in the model represent data
jags.data <- list('Y', #'Ybinom',
'muPsiCoef.tau', 'muDetCoef.tau', 't.tau', # params for prior distributions
'nSites', 'nSurveys', 'nPossSpp',
'nPsiCoef', 'nDetCoef',
'site.vars', 'X.array')
# Provide initial values for each cross-val run
# (Because of the way jags.parallel works with do.call, we need the two functions)
jags.inits113 <- function(nPossSpp=17, nSites=113){
list("muPsiCoef"=rnorm(nPsiCoef, 0, 1),
"muDetCoef"=rnorm(nDetCoef, 0, 1),
"halfsigmaPsiCoef"=runif(nPsiCoef, 0, 2),
"halfsigmaDetCoef"=runif(nDetCoef, 0, 2),
"Z"=matrix(1, nrow=17, ncol=113))
}
jags.inits112 <- function(nPossSpp=17, nSites=112){
list("muPsiCoef"=rnorm(nPsiCoef, 0, 1),
"muDetCoef"=rnorm(nDetCoef, 0, 1),
"halfsigmaPsiCoef"=runif(nPsiCoef, 0, 2),
"halfsigmaDetCoef"=runif(nDetCoef, 0, 2),
"Z"=matrix(1, nrow=17, ncol=112))
}
# nChains; nIterations; nBurn-in; nThin
nc=3;
ni = 15000 # 50 #
nb = 5000   #
nt = 10  #
n.folds <- 5
nSites.all <- nSites
## Randomize data order for CV tests
set.seed(2015)
kf = cumsum(c(1, kfcv(n.folds, nSites)))
randomized.sites <- sample(nSites)
cvY <- Y[, randomized.sites, ]
cvYbinom <- Ybinom[, randomized.sites]
cv.nSurveys <- nSurveys[randomized.sites]
cvSiteVars <- site.varsAll[, randomized.sites]
cvX.arrayAll <- X.arrayAll[, randomized.sites, ]
# Create list of model files:
models <- list()
models[[1]] <- "JAGS_models/KnownSppMSOM.Full.JAGS.R"
models[[2]] <- "JAGS_models/KnownSppMSOM.FullOccu.JAGS.R"
models[[3]] <- "JAGS_models/KnownSppMSOM.FullOccu2.JAGS.R"
models[[4]] <- "JAGS_models/KnownSppMSOM.NoCorrs.JAGS.R"
models[[5]] <- "JAGS_models/KnownSppMSOM.LandCoverSize.JAGS.R"
models[[6]] <- "JAGS_models/KnownSppMSOM.Combined.JAGS.R"
models[[7]] <- "JAGS_models/KnownSppMSOM.Reservoirs.JAGS.R"
models[[8]] <- "JAGS_models/KnownSppMSOM.Stream.JAGS.R"
models[[9]] <- "JAGS_models/KnownSppMSOM.Size.JAGS.R"
models[[10]] <- "JAGS_models/KnownSppMSOM.NoCorrs2.JAGS.R"
models[[11]] <- "JAGS_models/KnownSppMSOM.Combined2.JAGS.R"
models[[12]] <- "JAGS_models/KnownSppMSOM.LandCoverSize.JAGS.R"
models[[13]] <- "JAGS_models/KnownSppMSOM.AltSize.JAGS.R"
models[[14]] <- "JAGS_models/KnownSppMSOM.AltStream.JAGS.R"
models[[15]] <- "JAGS_models/KnownSppMSOM.SimpleSize.JAGS.R"
models[[16]] <- "JAGS_models/KnownSppMSOM.SimpleSize2.JAGS.R"
models[[17]] <- "JAGS_models/KnownSppMSOM.SimpleAltStream.JAGS.R"
models[[18]] <- "JAGS_models/KnownSppMSOM.SimpleAltStream2.JAGS.R"
models[[19]] <- "JAGS_models/KnownSppMSOM.SimpleLandCoverSize.JAGS.R"
models[[20]] <- "JAGS_models/KnownSppMSOM.SimpleLandCoverSize2.JAGS.R"
models[[21]] <- "JAGS_models/KnownSppMSOM.SimpleSizeCount.JAGS.R"
models[[22]] <- "JAGS_models/KnownSppMSOM.SimpleSizeCountNoYear.JAGS.R"
models[[23]] <- "JAGS_models/KnownSppMSOM.SimpleSize2.JAGS.R"
models[[24]] <- "JAGS_models/KnownSppMSOM.SimpleSizeCountNoYear.JAGS.R"
models[[25]] <- "JAGS_models/KnownSppMSOM.SimpleSize2noYr.JAGS.R"
models[[26]] <- "JAGS_models/KnownSppMSOM.SimpleSizeNoYr.JAGS.R"
models[[27]] <- "JAGS_models/KnownSppMSOM.SimpleAltStream2noYr.JAGS.R"
models[[28]] <- "JAGS_models/KnownSppMSOM.SimpleSizeNoYrConnect.JAGS.R"
### Run the cross-validation -----------------
Probs <- list()
cv.stats <- array(NA, dim=c(n.folds, nModels, 4))
out.list <- list()  # save all output.
## Create probability expressions
tmp <- createExpressionsArk()
expressPsi <- tmp$expressPsi
expressDet <- tmp$expressDet
for (fold in 1:n.folds){
# out.list <-  mclapply(1:n.folds, runCV, mc.cores=5)
# #out.list <-  foreach(fold = 1:n.folds, .packages="R2jags") %dopar% {
#   runCV <- function(){
Probs[[fold]] <- list()
test <- c(kf[fold]:(kf[fold + 1]-1) ) # test = "testing data"
cv.nSurveys.test <- cv.nSurveys[test]
testY <- cvY[, test, 1:max(cv.nSurveys.test)]
## save output in lists for organization:
out <- list()
# Use a different inits function depending on number of sites in training data
if (nSites.all - length(test) == 113){
jags.inits <- jags.inits113
}else{
jags.inits <- jags.inits112
}
# Fit the models to the training data set --------
# First re-create the data:
Y            <- cvY[, -test, ];
Ybinom       <- cvYbinom[, -test];
nSites       <- nSites.all - length(test);
nSurveys     <- cv.nSurveys[-test];
site.vars    <- cvSiteVars[, -test];
X.array      <- cvX.arrayAll[, -test, ]
### Fit Models in a loop
cat("Starting fold", fold, "\n")
cat("Y dim = ", dim(Y), "\n")
# print(jags.inits, "\n")
for (i in 24:nModels){
nPsiCoef <- nPsiList[[i]]  # elev + intecept
nDetCoef <- nDetList[[i]] # year, elev
out[[i]] <- do.call(jags.parallel, list(jags.data, jags.inits, params,
models[[i]],
nc, ni, nb, nt));
#     out[[i]] <- jags(jags.data, jags.inits, params,
#                      models[[i]], nc, ni, nb, nt);
cat("Mod ", i, "done!\n")
}
#  return(out)
save.image("/Volumes/CPW_Work/Optimum Sampling/Ark_Optimal_bwa/Output_Files/CrossValProbs2.RData") # save often in case it crashes
# Process the output:
for (i in 24:nModels) {
Probs[[fold]][[i]] <- derivePsiDetect(out[[i]],
expressPsi=expressPsi[[i]],
expressDet=expressDet[[i]],
nPossSpp=nPossSpp,
nSites=length(test),
nSurveys=cv.nSurveys.test )
score01 <- mean( apply(out[[i]]$BUGSoutput$sims.list$score01ij,
c(2, 3), sum, na.rm=T) )
other.scores <- calcCrossVal(testY, Probs[[fold]][[i]],
nPossSpp=nPossSpp, nSites=length(test),
nSurveys=cv.nSurveys.test)
cv.stats[fold, i, ] <- c(score01, other.scores )
cat("0-1 score \t Deviance \t AUC \t Brier \n")
print(round(cv.stats[fold, i, ], 2))
write.table(t(c(paste("fold", fold, sep=""),
paste("mod", i, sep=""),
cv.stats[fold, i, ])),
"/Volumes/CPW_Work/Optimum Sampling/Ark_Optimal_bwa/Output_Files/CrossValStats2.csv", append=T, sep=",",
row.names=FALSE, col.names=FALSE)
}
out.list[[i]] <- out
}
save.image("/Volumes/CPW_Work/Optimum Sampling/Ark_Optimal_bwa/Output_Files/CrossValProbs2.RData") # save often in case it crashes
# Cross-val stats are from saved .csv file.
crossVal.df <- read.csv("/Volumes/CPW_Work/Optimum Sampling/Ark_Optimal_bwa/Output_Files/CrossValStats2.csv", header=F)
### Table of CV values for all folds and all models: (Table C.1 in Appendix C)
head(crossVal.df)
## Take the average over the folds to get the reported statistics (Table 2)
crossVal.means <- aggregate(crossVal.df[, -c(1, 2)], by=list(Model = crossVal.df$V2), mean)
names(crossVal.means)[2:5] <- c("score01", "deviance", "AUC", "Brier")
crossVal.means[order(crossVal.means$deviance), ]
write.csv(crossVal.means, "/Volumes/CPW_Work/Optimum Sampling/Ark_Optimal_bwa/Output_Files/CrossValMeans2.csv", row.names = F)
